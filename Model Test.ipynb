{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a class or function to train, test, and store results for \n",
    "- Decision Tree\n",
    "- Random Forest\n",
    "- Support Vector Machine\n",
    "- TensorFlow Network\n",
    "\n",
    "It needs to:\n",
    " - accept four inputs `X_train`, `y_train`, `X_test`, and `y_test`, \n",
    " - train the model on `X_train` and `y_train`, \n",
    " - score the results using `X_test` and `y_test`\n",
    " - Print out the confusion matrix for each of the models, and \n",
    " - Return the results of the scoring as Python dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "AcquisitionColumnNames = (\n",
    "    \"LOAN_ID\", \"ORIG_CHN\", \"Seller.Name\", \n",
    "    \"ORIG_RT\", \"ORIG_AMT\", \"ORIG_TRM\", \"ORIG_DTE\",\n",
    "    \"FRST_DTE\", \"OLTV\", \"OCLTV\", \"NUM_BO\", \n",
    "    \"DTI\", \"CSCORE_B\", \"FTHB_FLG\", \"PURPOSE\", \n",
    "    \"PROP_TYP\", \"NUM_UNIT\", \"OCC_STAT\", \"STATE\", \"ZIP_3\", \n",
    "    \"MI_PCT\", \"Product.Type\", \"CSCORE_C\", \"MI_TYPE\", \n",
    "    \"RELOCATION_FLG\"\n",
    ")\n",
    "\n",
    "PerformanceColumnNames = (\n",
    "    \"LOAN_ID\", \"Monthly.Rpt.Prd\", \"Servicer.Name\", \n",
    "    \"LAST_RT\", \"LAST_UPB\", \"Loan.Age\", \"Months.To.Legal.Mat\", \n",
    "    \"Adj.Month.To.Mat\", \"Maturity.Date\", \"MSA\", \n",
    "    \"Delq.Status\", \"MOD_FLAG\", \"Zero.Bal.Code\", \n",
    "    \"ZB_DTE\", \"LPI_DTE\", \"FCC_DTE\",\"DISP_DT\", \n",
    "    \"FCC_COST\", \"PP_COST\", \"AR_COST\", \"IE_COST\", \n",
    "    \"TAX_COST\", \"NS_PROCS\",\"CE_PROCS\", \"RMW_PROCS\", \n",
    "    \"O_PROCS\", \"NON_INT_UPB\", \"PRIN_FORG_UPB_FHFA\", \n",
    "    \"REPCH_FLAG\", \"PRIN_FORG_UPB_OTH\", \"TRANSFER_FLG\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/DanWang/anaconda3/envs/tensorflow/lib/python3.5/site-packages/IPython/core/interactiveshell.py:2785: DtypeWarning: Columns (14,15,16) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "acquisition_data_path = \"./../FannieMae/2010Q1/Acquisition_2010Q1.txt\"\n",
    "performance_data_path = \"../FannieMae/2010Q1/Performance_2010Q1.txt\"\n",
    "acquisition_df = pd.read_csv(\n",
    "    acquisition_data_path,\n",
    "    names=AcquisitionColumnNames,\n",
    "    header=None,\n",
    "    sep=\"|\"\n",
    ")\n",
    "performance_df = pd.read_csv(\n",
    "    performance_data_path,\n",
    "    names=PerformanceColumnNames,\n",
    "    header=None,\n",
    "    sep=\"|\",\n",
    "#     nrows = 10000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{nan, '52', '22', '34', '67', '89', '94', '73', '99', '3', '88', '49', '46', '87', '65', '36', '60', '56', '13', '97', '95', '24', '43', '39', '5', '0', '9', '17', '30', '75', '28', '50', '31', '15', '35', '68', '66', '48', '47', '2', '44', '62', '91', '18', '8', '23', '41', '55', '53', '98', '10', '77', '74', '80', '32', '63', '70', '7', '40', '29', '58', '16', '27', '92', '61', '1', '54', '4', '57', '84', '81', '76', 'X', '64', '79', '11', '21', '6', '78', '59', '38', '25', '19', '82', '96', '85', '93', '86', '72', '14', '33', '71', '26', '51', '20', '83', '42', '12', '37', '69', '90', '45'}\n"
     ]
    }
   ],
   "source": [
    "DS = set(performance_df['Delq.Status'])\n",
    "print(DS)\n",
    "mapper = {}\n",
    "for ds in DS:\n",
    "    try:\n",
    "        mapper[ds] = int(ds)\n",
    "    except:\n",
    "        mapper[ds] = -1\n",
    "\n",
    "performance_df['Delq.Status'] = performance_df['Delq.Status'].map(mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1  0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22\n",
      " 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46\n",
      " 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70\n",
      " 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94\n",
      " 95 96 97 98 99]\n"
     ]
    }
   ],
   "source": [
    "V, C = np.unique(performance_df['Delq.Status'], return_counts=True)\n",
    "print(V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "loans = performance_df.groupby(\"LOAN_ID\", sort=True)['Delq.Status'].max()\n",
    "\n",
    "ID_To_Delinq = {}\n",
    "\n",
    "for row in loans.iteritems():\n",
    "    loan_id, delinq = row\n",
    "    ID_To_Delinq[loan_id] = delinq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapper(row):\n",
    "    return ID_To_Delinq.get(row[\"LOAN_ID\"], -1)\n",
    "\n",
    "acquisition_df['MAX_DELINQ'] = acquisition_df.apply(mapper, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "V, C = np.unique(acquisition_df['MAX_DELINQ'], return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "FCC_DTE = performance_df['FCC_DTE'].notna()\n",
    "\n",
    "forclosed = performance_df[FCC_DTE]\n",
    "\n",
    "FORECLOSURES = {}\n",
    "\n",
    "for row in forclosed.iterrows():\n",
    "    row = row[1]\n",
    "    FORECLOSURES[row['LOAN_ID']] = row['FCC_DTE']\n",
    "\n",
    "FORCLOSED = set(forclosed['LOAN_ID'])\n",
    "\n",
    "def mapper(row):\n",
    "    # return FORECLOSURES.get(row['LOAN_ID'], \"NO_FCC\")\n",
    "    return int(row['LOAN_ID'] in FORCLOSED)\n",
    "\n",
    "acquisition_df['FCC'] = acquisition_df.apply(mapper, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0, 1}\n"
     ]
    }
   ],
   "source": [
    "print(set(acquisition_df['FCC']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "V, C = np.unique(\n",
    "    performance_df['Monthly.Rpt.Prd'], \n",
    "    return_counts=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_date = performance_df['Monthly.Rpt.Prd'] == \"01/01/2015\"\n",
    "next_date   = performance_df['Monthly.Rpt.Prd'] == \"01/01/2016\"\n",
    "\n",
    "date_df = performance_df[actual_date]\n",
    "next_df = performance_df[next_date]\n",
    "\n",
    "Delinquency = {}\n",
    "Next_Delinquency = {}\n",
    "\n",
    "for row in date_df.iterrows():\n",
    "    row = row[1]\n",
    "    Delinquency[row['LOAN_ID']] = ID_To_Delinq.get(row[\"LOAN_ID\"], -1)\n",
    "    \n",
    "for row in next_df.iterrows():\n",
    "    row = row[1]\n",
    "    Next_Delinquency[row['LOAN_ID']] = ID_To_Delinq.get(row['LOAN_ID'], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapper(row):\n",
    "    return Delinquency.get(row[\"LOAN_ID\"], -1)\n",
    "\n",
    "def next_mapper(row):\n",
    "    return Next_Delinquency.get(row['LOAN_ID'], -1)\n",
    "\n",
    "acquisition_df['DELINQ_DATE'] = acquisition_df.apply(mapper, axis=1)\n",
    "\n",
    "acquisition_df['DELINQ_NEXT'] = acquisition_df.apply(next_mapper, axis=1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{20303}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/DanWang/anaconda3/envs/tensorflow/lib/python3.5/site-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "delinq = acquisition_df['DELINQ_DATE'] > 0\n",
    "delinq_df = acquisition_df[delinq]\n",
    "\n",
    "print({len(delinq_df.index)})\n",
    "\n",
    "def check_date_range(row):\n",
    "    return row['DELINQ_NEXT'] >= row['DELINQ_DATE']\n",
    "\n",
    "delinq_df['DELINQ_DELTA'] = delinq_df.apply(\n",
    "    check_date_range,\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False  |  2219\n",
      "True  |  18084\n"
     ]
    }
   ],
   "source": [
    "V, C = np.unique(delinq_df['DELINQ_DELTA'], return_counts=True)\n",
    "\n",
    "for v, c in zip(V, C):\n",
    "    print(v, \" | \", c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20038, 4)\n",
      "(20038, 1)\n",
      "(20038, 5)\n",
      "(20038, 4)\n",
      "(20038, 1)\n",
      "Train Number: 18034\n",
      "X_Train: (18034, 4)\n",
      "X_Test: {(2004, 4)}\n",
      "====================\n",
      "y_Train: {(18034, 1)}\n",
      "y_Test: {(2004, 1)}\n",
      "0.0  |  19397\n",
      "1.0  |  641\n",
      "[0. 1.]\n"
     ]
    }
   ],
   "source": [
    "df = delinq_df\n",
    "\n",
    "DEL_NOTNAN = df[\"DELINQ_DELTA\"].notna()\n",
    "df = df[DEL_NOTNAN]\n",
    "OLTV = df['OLTV'].notna()\n",
    "df = df[OLTV]\n",
    "CS = df['CSCORE_B'].notna()\n",
    "df = df[CS]\n",
    "DTI = df['DTI'].notna()\n",
    "df = df[DTI]\n",
    "\n",
    "credit_score  = np.array(df['CSCORE_B'])\n",
    "credit_score /= np.max(credit_score)\n",
    "\n",
    "loan_to_value = np.array(df['OLTV'])\n",
    "\n",
    "loan_to_value = loan_to_value/np.max(loan_to_value)\n",
    "\n",
    "debt_to_income= np.array(df['DTI'])\n",
    "debt_to_income /= np.max(debt_to_income)\n",
    "\n",
    "delinq_value  = np.array(df['DELINQ_DATE'])\n",
    "\n",
    "max_delinq    = np.array(df['DELINQ_DELTA'])\n",
    "\n",
    "foreclosed    = np.array(df['FCC'])\n",
    "X = np.array(\n",
    "    [\n",
    "        credit_score, \n",
    "        loan_to_value, \n",
    "        debt_to_income, \n",
    "        delinq_value\n",
    "    ]\n",
    ").transpose()\n",
    "\n",
    "\n",
    "y = np.array([foreclosed]).transpose()\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n",
    "Total = np.hstack([X, y])\n",
    "print(Total.shape)\n",
    "np.random.shuffle(Total)\n",
    "\n",
    "X = Total[:, :4]\n",
    "y = Total[:, 4:]\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n",
    "prop = 0.9\n",
    "train_num = int(prop * len(Total))\n",
    "print(\"Train Number:\", train_num)\n",
    "\n",
    "X_train, X_test = X[:train_num], X[train_num:]\n",
    "y_train, y_test = y[:train_num], y[train_num:]\n",
    "\n",
    "print(\"X_Train:\", X_train.shape)\n",
    "print(\"X_Test:\", {X_test.shape})\n",
    "print(\"==\"*10)\n",
    "print(\"y_Train:\", {y_train.shape})\n",
    "print(\"y_Test:\",  {y_test.shape})\n",
    "\n",
    "V, C = np.unique(y, return_counts=True)\n",
    "class_weight = {}\n",
    "for v, c in zip(V, C):\n",
    "    prop = c / len(y)\n",
    "    class_weight[v] = 1 - prop\n",
    "    print(v, \" | \", c)\n",
    "\n",
    "class_names = np.unique(y)\n",
    "\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9600798403193613\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1902,   36],\n",
       "       [  44,   22]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "from sklearn.metrics import confusion_matrix\n",
    "dtc = tree.DecisionTreeClassifier(class_weight=class_weight)\n",
    "dtc.fit(\n",
    "    X_train, y_train\n",
    ")\n",
    "print(dtc.score(X_test, y_test))\n",
    "y_pred = dtc.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1896   42]\n",
      " [  45   21]]\n"
     ]
    }
   ],
   "source": [
    "dtc = tree.DecisionTreeClassifier()\n",
    "dtc.fit(X_train, y_train)\n",
    "y_pred = dtc.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print (cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLtest:\n",
    "    def __init__(self, X_train, y_train, X_test, y_test):\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.X_test = X_test\n",
    "        self.y_test = y_test\n",
    "        \n",
    "    def dzt(self, class_weight=class_weight):\n",
    "        dtc = tree.DecisionTreeClassifier(class_weight = class_weight)\n",
    "        self.clf = dtc\n",
    "        return self.clf\n",
    "    \n",
    "    def rf(self, n_estimators=100, max_depth=5):\n",
    "        clf = RandomForestClassifier(n_estimators = n_estimators, max_depth = max_depth)\n",
    "        self.clf = clf\n",
    "        return self.clf\n",
    "    \n",
    "    def svm(self):\n",
    "        clf = SVC(gamma='auto')\n",
    "        self.clf = clf\n",
    "        return self.clf\n",
    "    \n",
    "    def mlp(self, solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(100, 10)):\n",
    "        clf = MLPClassifier(solver = solver, alpha = alpha, hidden_layer_sizes = hidden_layer_sizes)\n",
    "        self.clf = clf\n",
    "        return self.clf\n",
    "    \n",
    "    def train(self):\n",
    "        self.clf.fit(self.X_train, self.y_train)\n",
    "        return self.clf\n",
    "    \n",
    "    def test(self):\n",
    "        y_pred = self.clf.predict(self.X_test)\n",
    "        cm = confusion_matrix(self.y_test, y_pred)\n",
    "        print ('confusion matrix: \\n', cm)\n",
    "        return {'test acc' : clf.score(self.X_test, y_test)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix: \n",
      " [[1904   34]\n",
      " [  47   19]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test acc': 0.9655688622754491}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Testclass = MLtest(X_train, y_train, X_test, y_test)\n",
    "Testclass.dzt(class_weight=class_weight)\n",
    "Testclass.train()\n",
    "Testclass.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/DanWang/anaconda3/envs/tensorflow/lib/python3.5/site-packages/ipykernel_launcher.py:29: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix: \n",
      " [[1934    4]\n",
      " [  61    5]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test acc': 0.9655688622754491}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Testclass.rf(n_estimators=100, max_depth=5)\n",
    "Testclass.train()\n",
    "Testclass.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/DanWang/anaconda3/envs/tensorflow/lib/python3.5/site-packages/sklearn/utils/validation.py:752: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix: \n",
      " [[1932    6]\n",
      " [  64    2]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test acc': 0.9655688622754491}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Testclass.svm()\n",
    "Testclass.train()\n",
    "Testclass.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/DanWang/anaconda3/envs/tensorflow/lib/python3.5/site-packages/sklearn/neural_network/multilayer_perceptron.py:916: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix: \n",
      " [[1929    9]\n",
      " [  59    7]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test acc': 0.9655688622754491}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Testclass.mlp(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(100, 10))\n",
    "Testclass.train()\n",
    "Testclass.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
